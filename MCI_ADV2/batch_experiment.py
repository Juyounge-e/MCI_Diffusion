#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ë°°ì¹˜ ì‹¤í—˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°

ëŒ€ì „ ê·¸ë¦¬ë“œ ì „ì²´ì— ëŒ€í•´ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ë° ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
"""

import os
import sys
import yaml
import pandas as pd
import logging
from datetime import datetime
from pathlib import Path
from make_csv_yaml_dynamic import ScenarioGenerator
import subprocess

# Windows ì½˜ì†” UTF-8 ì„¤ì •
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')


class BatchExperimentOrchestrator:
    """ë°°ì¹˜ ì‹¤í—˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""

    def __init__(self, base_path, grid_metadata_path, config_template_path):
        """
        ì´ˆê¸°í™”

        Args:
            base_path: í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
            grid_metadata_path: grid_metadata.csv ê²½ë¡œ
            config_template_path: config.yaml í…œí”Œë¦¿ ê²½ë¡œ
        """
        self.base_path = Path(base_path)

        # Grid metadata ë¡œë“œ
        try:
            self.grid_metadata = pd.read_csv(grid_metadata_path)
            print(f"âœ… Grid metadata ë¡œë“œ: {len(self.grid_metadata)}ê°œ ê·¸ë¦¬ë“œ")
        except FileNotFoundError:
            raise FileNotFoundError(f"âŒ Grid metadata íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {grid_metadata_path}")
        except Exception as e:
            raise Exception(f"âŒ Grid metadata ë¡œë“œ ì‹¤íŒ¨: {e}")

        # config.yaml ë¡œë“œ
        try:
            with open(config_template_path, 'r', encoding='utf-8') as f:
                self.config_template = yaml.safe_load(f)
            print(f"âœ… Config í…œí”Œë¦¿ ë¡œë“œ: {config_template_path}")
        except FileNotFoundError:
            raise FileNotFoundError(f"âŒ Config íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_template_path}")
        except Exception as e:
            raise Exception(f"âŒ Config ë¡œë“œ ì‹¤íŒ¨: {e}")

        # ì‹¤í—˜ ID ìƒì„±: exp_YYYYMMDD_HHMMSS í˜•ì‹ (í†µì¼)
        self.exp_id = f"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        # ì‹œë‚˜ë¦¬ì˜¤ í´ë” (CSV/YAML ì €ì¥)
        self.scenarios_base = self.base_path / "scenarios" / self.exp_id
        self.scenarios_base.mkdir(parents=True, exist_ok=True)

        # ê²°ê³¼ í´ë”
        self.results_base = self.base_path / "results" / self.exp_id
        self.results_base.mkdir(parents=True, exist_ok=True)

        # ë¡œê·¸ í´ë”
        self.logs_base = self.base_path / "experiment_logs"
        self.logs_base.mkdir(parents=True, exist_ok=True)

        # ë¡œê¹… ì„¤ì •
        self.setup_logging()

        # ì§„í–‰ ìƒí™© ì¶”ì 
        self.total_grids = len(self.grid_metadata)
        self.completed_grids = 0
        self.failed_grids = []

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶”ì  (grid_id -> {scenario_gen_time, sim_time, api_calls, status, failure_reason})
        self.performance_metrics = {}

    def setup_logging(self):
        """ë¡œê¹… ì„¤ì • (íŒŒì¼ + ì½˜ì†”)"""
        log_file = self.logs_base / f"{self.exp_id}.log"

        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
        for handler in logging.root.handlers[:]:
            logging.root.removeHandler(handler)

        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)

    def save_experiment_metadata(self, include_performance=False):
        """ì‹¤í—˜ ë©”íƒ€ë°ì´í„° ì €ì¥

        Args:
            include_performance: Trueì´ë©´ ì„±ëŠ¥ ë©”íŠ¸ë¦­ í¬í•¨ (ì‹¤í—˜ ì¢…ë£Œ í›„)
        """
        # ê·¸ë¦¬ë“œ ë©”íƒ€ë°ì´í„°ì— íŒŒë¼ë¯¸í„° ì¶”ê°€
        metadata = self.grid_metadata.copy()
        metadata['experiment_id'] = self.exp_id
        metadata['incident_size'] = self.config_template['entity_info']['patient']['incident_size']
        metadata['amb_velocity'] = self.config_template['entity_info']['ambulance']['velocity']
        metadata['uav_velocity'] = self.config_template['entity_info']['uav']['velocity']
        metadata['total_samples'] = self.config_template['run_setting']['totalSamples']
        metadata['random_seed'] = self.config_template['run_setting']['random_seed']
        metadata['is_use_time'] = self.config_template['entity_info']['ambulance'].get('is_use_time', True)
        metadata['uav_size'] = 0  # ê³ ì •ê°’

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶”ê°€ (ì‹¤í—˜ ì¢…ë£Œ í›„)
        if include_performance and self.performance_metrics:
            metadata['scenario_gen_time_sec'] = metadata['grid_id'].map(
                lambda gid: self.performance_metrics.get(gid, {}).get('scenario_gen_time_sec', None)
            )
            metadata['simulation_time_sec'] = metadata['grid_id'].map(
                lambda gid: self.performance_metrics.get(gid, {}).get('simulation_time_sec', None)
            )
            metadata['api_call_count'] = metadata['grid_id'].map(
                lambda gid: self.performance_metrics.get(gid, {}).get('api_call_count', None)
            )
            metadata['status'] = metadata['grid_id'].map(
                lambda gid: self.performance_metrics.get(gid, {}).get('status', 'not_processed')
            )
            metadata['failure_reason'] = metadata['grid_id'].map(
                lambda gid: self.performance_metrics.get(gid, {}).get('failure_reason', None)
            )

            # Experiment-level summary columns (repeat per row)
            success_mask = metadata['status'] == 'success'
            avg_scenario_gen = metadata.loc[success_mask, 'scenario_gen_time_sec'].dropna().mean()
            avg_sim_time = metadata.loc[success_mask, 'simulation_time_sec'].dropna().mean()
            avg_api_calls = metadata.loc[success_mask, 'api_call_count'].dropna().mean()
            total_grids = len(metadata)
            success_count = int(success_mask.sum())
            success_rate = (success_count / total_grids * 100) if total_grids > 0 else 0.0

            insert_at = metadata.columns.get_loc('failure_reason') + 1
            summary_cols = [
                'í‰ê·  ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì‹œê°„',
                'í‰ê·  ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì‹œê°„',
                'í‰ê·  API í˜¸ì¶œ ê±´ ìˆ˜',
                'ì „ì²´ ê·¸ë¦¬ë“œ ìˆ˜',
                'ì‹¤í—˜ ì„±ê³µ ìˆ˜',
                'ì„±ê³µìœ¨'
            ]
            summary_vals = [
                avg_scenario_gen,
                avg_sim_time,
                avg_api_calls,
                total_grids,
                success_count,
                success_rate
            ]
            for offset, (col, val) in enumerate(zip(summary_cols, summary_vals)):
                metadata.insert(insert_at + offset, col, val)

        # ì €ì¥
        metadata_path = self.scenarios_base / "experiment_metadata.csv"
        metadata.to_csv(metadata_path, index=False, encoding='utf-8-sig')
        self.logger.info(f"ğŸ“‹ ì‹¤í—˜ ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")

    def run_experiment(self):
        """ë©”ì¸ ì‹¤í—˜ ë£¨í”„"""
        self.logger.info(f"{'='*70}")
        self.logger.info(f"ğŸš€ ë°°ì¹˜ ì‹¤í—˜ ì‹œì‘: {self.exp_id}")
        self.logger.info(f"{'='*70}")
        self.logger.info(f"ì´ ê·¸ë¦¬ë“œ ìˆ˜: {self.total_grids}")
        self.logger.info(f"ì‹œë‚˜ë¦¬ì˜¤ ì €ì¥: {self.scenarios_base}")
        self.logger.info(f"ê²°ê³¼ ì €ì¥: {self.results_base}")
        self.logger.info(f"ë¡œê·¸ ì €ì¥: {self.logs_base / f'{self.exp_id}.log'}")
        self.logger.info(f"{'='*70}\n")

        # ë©”íƒ€ë°ì´í„° ì €ì¥
        self.save_experiment_metadata()

        # ê° ê·¸ë¦¬ë“œ ì²˜ë¦¬
        for idx, row in self.grid_metadata.iterrows():
            grid_id = row['grid_id']
            lat = row['latitude']
            lon = row['longitude']

            try:
                self.logger.info(f"\n[{idx+1}/{self.total_grids}] ğŸ”„ ê·¸ë¦¬ë“œ {grid_id} ì²˜ë¦¬ ì¤‘: ({lat:.6f}, {lon:.6f})")

                self.process_grid(grid_id, lat, lon)

                self.completed_grids += 1
                progress_pct = (self.completed_grids / self.total_grids) * 100
                self.logger.info(f"âœ… ê·¸ë¦¬ë“œ {grid_id} ì™„ë£Œ ({self.completed_grids}/{self.total_grids}, {progress_pct:.1f}%)")

            except Exception as e:
                error_str = str(e)
                self.failed_grids.append((grid_id, lat, lon, error_str))

                # ì‹¤íŒ¨ ì›ì¸ ë¶„ë¥˜
                if "NoSegment" in error_str or "ë‚´ì— ë„ë¡œ ì—†ìŒ" in error_str:
                    failure_type = "ê²©ì˜¤ì§€ (ë„ë¡œ ì—†ìŒ)"
                elif "NoRoute" in error_str or "ë„ë¡œ ì—°ê²° ì•ˆë¨" in error_str:
                    failure_type = "ë„ë¡œ ì—°ê²° ì•ˆë¨"
                elif "API íƒ€ì„ì•„ì›ƒ" in error_str or "timeout" in error_str.lower():
                    failure_type = "API íƒ€ì„ì•„ì›ƒ"
                elif "Rate limit" in error_str:
                    failure_type = "API Rate Limit ì´ˆê³¼"
                else:
                    failure_type = "ê¸°íƒ€ ì˜¤ë¥˜"

                # ì‹¤íŒ¨ ë©”íŠ¸ë¦­ ê¸°ë¡
                self.performance_metrics[grid_id] = {
                    'scenario_gen_time_sec': None,
                    'simulation_time_sec': None,
                    'api_call_count': None,
                    'status': 'failed',
                    'failure_reason': f"{failure_type}: {error_str[:200]}"  # ìµœëŒ€ 200ì
                }

                self.logger.error(f"âŒ ê·¸ë¦¬ë“œ {grid_id} ì‹¤íŒ¨ [{failure_type}]: {error_str}")
                continue

        # ìµœì¢… ìš”ì•½
        self.print_summary()

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ í¬í•¨í•œ ë©”íƒ€ë°ì´í„° ì¬ì €ì¥
        self.logger.info(f"\nğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ í¬í•¨í•œ ë©”íƒ€ë°ì´í„° ì €ì¥ ì¤‘...")
        self.save_experiment_metadata(include_performance=True)

    def process_grid(self, grid_id, latitude, longitude):
        """
        ë‹¨ì¼ ê·¸ë¦¬ë“œ ì²˜ë¦¬

        Args:
            grid_id: ê·¸ë¦¬ë“œ ID
            latitude: ê·¸ë¦¬ë“œ ì¤‘ì‹¬ì  ìœ„ë„
            longitude: ê·¸ë¦¬ë“œ ì¤‘ì‹¬ì  ê²½ë„
        """
        import time

        # 1. ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± (CSV + YAML)
        self.logger.info(f"  ğŸ“ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì¤‘...")
        scenario_gen_start = time.time()

        generator = ScenarioGenerator(
            base_path=str(self.base_path),
            experiment_id=self.exp_id
        )

        # config.yamlì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        incident_size = self.config_template['entity_info']['patient']['incident_size']
        amb_velocity = self.config_template['entity_info']['ambulance']['velocity']
        uav_velocity = self.config_template['entity_info']['uav']['velocity']
        total_samples = self.config_template['run_setting']['totalSamples']
        random_seed = self.config_template['run_setting']['random_seed']
        is_use_time = self.config_template['entity_info']['ambulance'].get('is_use_time', True)
        duration_coeff = self.config_template['entity_info']['ambulance'].get('duration_coeff', 1.0)

        # ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± (routes í´ë” ì—†ìŒ)
        config_path, api_calls = generator.generate_scenario(
            latitude=latitude,
            longitude=longitude,
            incident_size=incident_size,
            amb_size=incident_size,  # ê¸°ì¡´ íŒŒë¼ë¯¸í„° ì‚¬ìš©
            uav_size=0,  # UAV 0ëŒ€ ê³ ì •
            amb_velocity=amb_velocity,
            uav_velocity=uav_velocity,
            total_samples=total_samples,
            random_seed=random_seed,
            is_use_time=is_use_time,
            amb_handover_time=0,
            uav_handover_time=0,
            duration_coeff=duration_coeff
        )

        scenario_gen_time = round(time.time() - scenario_gen_start, 2)
        self.logger.info(f"  âœ… ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì™„ë£Œ ({scenario_gen_time}ì´ˆ, API í˜¸ì¶œ: {api_calls}íšŒ)")

        # 2. ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
        self.logger.info(f"  ğŸ® ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì¤‘...")
        sim_start = time.time()

        result = subprocess.run(
            [sys.executable, str(self.base_path / "main.py"),
             "--config_path", config_path],
            cwd=str(self.base_path),
            capture_output=True,
            text=True,
            timeout=1200,  # 20ë¶„ íƒ€ì„ì•„ì›ƒ
            encoding='utf-8'
        )

        if result.returncode != 0:
            raise RuntimeError(f"ì‹œë®¬ë ˆì´ì…˜ ì‹¤íŒ¨: {result.stderr}")

        sim_time = round(time.time() - sim_start, 2)
        self.logger.info(f"  âœ… ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ ({sim_time}ì´ˆ)")

        # 3. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì €ì¥
        self.performance_metrics[grid_id] = {
            'scenario_gen_time_sec': scenario_gen_time,
            'simulation_time_sec': sim_time,
            'api_call_count': api_calls,
            'status': 'success',
            'failure_reason': None
        }

    def print_summary(self):
        """ìµœì¢… ìš”ì•½ ì¶œë ¥"""
        self.logger.info(f"\n{'='*70}")
        self.logger.info(f"ğŸ“Š ì‹¤í—˜ {self.exp_id} ì™„ë£Œ")
        self.logger.info(f"{'='*70}")
        self.logger.info(f"âœ… ì„±ê³µ: {self.completed_grids}/{self.total_grids}")
        self.logger.info(f"âŒ ì‹¤íŒ¨: {len(self.failed_grids)}")

        if self.failed_grids:
            # ì‹¤íŒ¨ ìœ í˜•ë³„ ë¶„ë¥˜
            failure_types = {}
            for grid_id, lat, lon, error in self.failed_grids:
                if "NoSegment" in error or "ë‚´ì— ë„ë¡œ ì—†ìŒ" in error:
                    failure_type = "ê²©ì˜¤ì§€ (ë„ë¡œ ì—†ìŒ)"
                elif "NoRoute" in error or "ë„ë¡œ ì—°ê²° ì•ˆë¨" in error:
                    failure_type = "ë„ë¡œ ì—°ê²° ì•ˆë¨"
                elif "API íƒ€ì„ì•„ì›ƒ" in error or "timeout" in error.lower():
                    failure_type = "API íƒ€ì„ì•„ì›ƒ"
                elif "Rate limit" in error:
                    failure_type = "API Rate Limit ì´ˆê³¼"
                else:
                    failure_type = "ê¸°íƒ€ ì˜¤ë¥˜"

                if failure_type not in failure_types:
                    failure_types[failure_type] = []
                failure_types[failure_type].append((grid_id, lat, lon, error))

            self.logger.info(f"\nì‹¤íŒ¨ ìœ í˜•ë³„ í†µê³„:")
            for failure_type, grids in failure_types.items():
                self.logger.info(f"  â€¢ {failure_type}: {len(grids)}ê±´")

            self.logger.info(f"\nì‹¤íŒ¨í•œ ê·¸ë¦¬ë“œ ìƒì„¸:")
            for grid_id, lat, lon, error in self.failed_grids[:10]:  # ìµœëŒ€ 10ê°œë§Œ ì¶œë ¥
                short_error = error[:100] + "..." if len(error) > 100 else error
                self.logger.info(f"  - ê·¸ë¦¬ë“œ {grid_id} ({lat:.6f}, {lon:.6f}): {short_error}")
            if len(self.failed_grids) > 10:
                self.logger.info(f"  ... ì™¸ {len(self.failed_grids) - 10}ê°œ (ì „ì²´ ëª©ë¡ì€ ë©”íƒ€ë°ì´í„° CSV ì°¸ì¡°)")

        success_rate = (self.completed_grids / self.total_grids * 100) if self.total_grids > 0 else 0
        self.logger.info(f"\nì„±ê³µë¥ : {success_rate:.1f}%")
        self.logger.info(f"{'='*70}\n")


def main():
    """ë©”ì¸ ì§„ì…ì """
    import argparse
    parser = argparse.ArgumentParser(description="ëŒ€ì „ ê·¸ë¦¬ë“œ ë°°ì¹˜ ì‹¤í—˜")
    parser.add_argument("--base_path", required=True, help="í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ")
    parser.add_argument("--grid_metadata", required=True, help="grid_metadata.csv ê²½ë¡œ")
    parser.add_argument("--config_template", default="config.yaml", help="config í…œí”Œë¦¿ ê²½ë¡œ")
    args = parser.parse_args()

    try:
        orchestrator = BatchExperimentOrchestrator(
            base_path=args.base_path,
            grid_metadata_path=args.grid_metadata,
            config_template_path=args.config_template
        )

        orchestrator.run_experiment()

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return 1

    return 0


if __name__ == "__main__":
    exit(main())
